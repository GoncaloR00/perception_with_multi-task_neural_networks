{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f19105e-f316-451c-8844-c378d0825e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_tensorrt\n",
    "\n",
    "# print(tensorrt.IBuilderConfig.max_workspace_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48919651-337d-4d05-b7a8-d6e1a63b791d",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = torch.jit.load(\"./models/yolov5s.torchscript\").to(\"cuda\")\n",
    "# load_model = torch.jit.load(\"./models/yolopv2.pt\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96a806fe-788e-4d00-a6f9-d033364a4b32",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m traced_model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mtrace(\u001b[43mload_model\u001b[49m, [torch\u001b[38;5;241m.\u001b[39mrandn((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m384\u001b[39m, \u001b[38;5;241m640\u001b[39m))\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_model' is not defined"
     ]
    }
   ],
   "source": [
    "traced_model = torch.jit.trace(load_model, [torch.randn((1, 3, 384, 640)).to(\"cuda\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff041ae3-5cac-4239-8f7f-8404d910533e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.device('cuda')\n",
    "load_model = load_model.half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a412af37-765e-48de-a2cf-d7323d758398",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [Torch-TensorRT] - For input x.1, found user specified input dtype as Float, however when inspecting the graph, the input type expected was inferred to be Half\n",
      "The compiler is going to use the user setting Float\n",
      "This conflict may cause an error at runtime due to partial compilation being enabled and therefore\n",
      "compatibility with PyTorch's data type convention is required.\n",
      "If you do indeed see errors at runtime either:\n",
      "- Remove the dtype spec for x.1\n",
      "- Disable partial compilation by setting require_full_compilation to True\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript, serialized code (most recent call last):\n  File \"code/__torch__/models/yolo.py\", line 59, in forward\n    model23 = self.model\n    _0 = getattr(model23, \"0\")\n    _25 = (_2).forward((_1).forward((_0).forward(x, ), ), )\n                                     ~~~~~~~~~~~ <--- HERE\n    _26 = (_4).forward((_3).forward(_25, ), )\n    _27 = (_6).forward((_5).forward(_26, ), )\n  File \"code/__torch__/models/common.py\", line 12, in forward\n    act = self.act\n    conv = self.conv\n    _0 = (act).forward((conv).forward(x, ), )\n                        ~~~~~~~~~~~~~ <--- HERE\n    return _0\nclass C3(Module):\n  File \"code/__torch__/torch/nn/modules/conv.py\", line 12, in forward\n    bias = self.bias\n    weight = self.weight\n    input = torch._convolution(x, weight, bias, [2, 2], [2, 2], [1, 1], False, [0, 0], 1, False, False, True, True)\n            ~~~~~~~~~~~~~~~~~~ <--- HERE\n    return input\n\nTraceback of TorchScript, original code (most recent call last):\n/home/gribeiro/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py(459): _conv_forward\n/home/gribeiro/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py(463): forward\n/home/gribeiro/.local/lib/python3.8/site-packages/torch/nn/modules/module.py(1488): _slow_forward\n/home/gribeiro/.local/lib/python3.8/site-packages/torch/nn/modules/module.py(1501): _call_impl\n/home/gribeiro/Tese/Modelos/yolov5/models/common.py(59): forward_fuse\n/home/gribeiro/.local/lib/python3.8/site-packages/torch/nn/modules/module.py(1488): _slow_forward\n/home/gribeiro/.local/lib/python3.8/site-packages/torch/nn/modules/module.py(1501): _call_impl\n/home/gribeiro/Tese/Modelos/yolov5/models/yolo.py(121): _forward_once\n/home/gribeiro/Tese/Modelos/yolov5/models/yolo.py(209): forward\n/home/gribeiro/.local/lib/python3.8/site-packages/torch/nn/modules/module.py(1488): _slow_forward\n/home/gribeiro/.local/lib/python3.8/site-packages/torch/nn/modules/module.py(1501): _call_impl\n/home/gribeiro/.local/lib/python3.8/site-packages/torch/jit/_trace.py(1056): trace_module\n/home/gribeiro/.local/lib/python3.8/site-packages/torch/jit/_trace.py(794): trace\n./export.py(123): export_torchscript\n./export.py(107): outer_func\n./export.py(580): run\n/home/gribeiro/.local/lib/python3.8/site-packages/torch/utils/_contextlib.py(115): decorate_context\n./export.py(668): main\n./export.py(673): <module>\nRuntimeError: Input type (CUDAFloatType) and weight type (CUDAHalfType) should be the same\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trt_model \u001b[38;5;241m=\u001b[39m \u001b[43mtorch_tensorrt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtorch_tensorrt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m384\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m640\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43menabled_precisions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncate_long_and_double\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch_tensorrt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDevice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda:0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkspace_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4194304\u001b[39;49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# torch_tensorrt.dtype.half\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch_tensorrt/_compile.py:133\u001b[0m, in \u001b[0;36mcompile\u001b[0;34m(module, ir, inputs, enabled_precisions, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m         logging\u001b[38;5;241m.\u001b[39mlog(\n\u001b[1;32m    129\u001b[0m             logging\u001b[38;5;241m.\u001b[39mLevel\u001b[38;5;241m.\u001b[39mInfo,\n\u001b[1;32m    130\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModule was provided as a torch.nn.Module, trying to script the module with torch.jit.script. In the event of a failure please preconvert your module to TorchScript\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    131\u001b[0m         )\n\u001b[1;32m    132\u001b[0m         ts_mod \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mscript(module)\n\u001b[0;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch_tensorrt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mts_mod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menabled_precisions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menabled_precisions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m target_ir \u001b[38;5;241m==\u001b[39m _IRType\u001b[38;5;241m.\u001b[39mfx:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    138\u001b[0m         torch\u001b[38;5;241m.\u001b[39mfloat16 \u001b[38;5;129;01min\u001b[39;00m enabled_precisions\n\u001b[1;32m    139\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m torch_tensorrt\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mhalf \u001b[38;5;129;01min\u001b[39;00m enabled_precisions\n\u001b[1;32m    140\u001b[0m     ):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch_tensorrt/ts/_compiler.py:139\u001b[0m, in \u001b[0;36mcompile\u001b[0;34m(module, inputs, input_signature, device, disable_tf32, sparse_weights, enabled_precisions, refit, debug, capability, num_avg_timing_iters, workspace_size, dla_sram_size, dla_local_dram_size, dla_global_dram_size, calibrator, truncate_long_and_double, require_full_compilation, min_block_size, torch_executed_ops, torch_executed_modules, allow_shape_tensors)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    113\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequire_full_compilation is enabled however the list of modules and ops to run in torch is not empty. Found: torch_executed_ops: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch_executed_ops\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, torch_executed_modules: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch_executed_modules\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    114\u001b[0m     )\n\u001b[1;32m    116\u001b[0m spec \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: inputs,\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_signature\u001b[39m\u001b[38;5;124m\"\u001b[39m: input_signature,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_shape_tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_shape_tensors,\n\u001b[1;32m    137\u001b[0m }\n\u001b[0;32m--> 139\u001b[0m compiled_cpp_mod \u001b[38;5;241m=\u001b[39m \u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_parse_compile_spec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m compiled_module \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39m_recursive\u001b[38;5;241m.\u001b[39mwrap_cpp_module(compiled_cpp_mod)\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m compiled_module\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript, serialized code (most recent call last):\n  File \"code/__torch__/models/yolo.py\", line 59, in forward\n    model23 = self.model\n    _0 = getattr(model23, \"0\")\n    _25 = (_2).forward((_1).forward((_0).forward(x, ), ), )\n                                     ~~~~~~~~~~~ <--- HERE\n    _26 = (_4).forward((_3).forward(_25, ), )\n    _27 = (_6).forward((_5).forward(_26, ), )\n  File \"code/__torch__/models/common.py\", line 12, in forward\n    act = self.act\n    conv = self.conv\n    _0 = (act).forward((conv).forward(x, ), )\n                        ~~~~~~~~~~~~~ <--- HERE\n    return _0\nclass C3(Module):\n  File \"code/__torch__/torch/nn/modules/conv.py\", line 12, in forward\n    bias = self.bias\n    weight = self.weight\n    input = torch._convolution(x, weight, bias, [2, 2], [2, 2], [1, 1], False, [0, 0], 1, False, False, True, True)\n            ~~~~~~~~~~~~~~~~~~ <--- HERE\n    return input\n\nTraceback of TorchScript, original code (most recent call last):\n/home/gribeiro/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py(459): _conv_forward\n/home/gribeiro/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py(463): forward\n/home/gribeiro/.local/lib/python3.8/site-packages/torch/nn/modules/module.py(1488): _slow_forward\n/home/gribeiro/.local/lib/python3.8/site-packages/torch/nn/modules/module.py(1501): _call_impl\n/home/gribeiro/Tese/Modelos/yolov5/models/common.py(59): forward_fuse\n/home/gribeiro/.local/lib/python3.8/site-packages/torch/nn/modules/module.py(1488): _slow_forward\n/home/gribeiro/.local/lib/python3.8/site-packages/torch/nn/modules/module.py(1501): _call_impl\n/home/gribeiro/Tese/Modelos/yolov5/models/yolo.py(121): _forward_once\n/home/gribeiro/Tese/Modelos/yolov5/models/yolo.py(209): forward\n/home/gribeiro/.local/lib/python3.8/site-packages/torch/nn/modules/module.py(1488): _slow_forward\n/home/gribeiro/.local/lib/python3.8/site-packages/torch/nn/modules/module.py(1501): _call_impl\n/home/gribeiro/.local/lib/python3.8/site-packages/torch/jit/_trace.py(1056): trace_module\n/home/gribeiro/.local/lib/python3.8/site-packages/torch/jit/_trace.py(794): trace\n./export.py(123): export_torchscript\n./export.py(107): outer_func\n./export.py(580): run\n/home/gribeiro/.local/lib/python3.8/site-packages/torch/utils/_contextlib.py(115): decorate_context\n./export.py(668): main\n./export.py(673): <module>\nRuntimeError: Input type (CUDAFloatType) and weight type (CUDAHalfType) should be the same\n"
     ]
    }
   ],
   "source": [
    "trt_model = torch_tensorrt.compile(\n",
    "    load_model,\n",
    "    inputs = [torch_tensorrt.Input((1, 3, 384, 640), dtype=torch.float32)],\n",
    "    enabled_precisions = {torch.float32},\n",
    "    truncate_long_and_double = True,\n",
    "    device = torch_tensorrt.Device(\"cuda:0\"),\n",
    "    workspace_size=4194304\n",
    ")\n",
    "# torch_tensorrt.dtype.half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2500362a-cae8-448b-ad09-d4f1be99bce9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter\n",
      "WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter\n",
      "WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter\n",
      "WARNING: [Torch-TensorRT] - Truncating weight (constant in the graph) from Int64 to Int32\n",
      "WARNING: [Torch-TensorRT] - Truncating weight (constant in the graph) from Int64 to Int32\n",
      "WARNING: [Torch-TensorRT] - Truncating weight (constant in the graph) from Int64 to Int32\n",
      "WARNING: [Torch-TensorRT] - Truncating weight (constant in the graph) from Int64 to Int32\n",
      "WARNING: [Torch-TensorRT] - Truncating weight (constant in the graph) from Int64 to Int32\n",
      "WARNING: [Torch-TensorRT] - Truncating weight (constant in the graph) from Int64 to Int32\n"
     ]
    }
   ],
   "source": [
    "trt_model_half = torch_tensorrt.compile(\n",
    "    load_model,\n",
    "    inputs = [torch.randn((1, 3, 384, 640), dtype=torch.float16)],\n",
    "    enabled_precisions = {torch.float16},\n",
    "    truncate_long_and_double = True,\n",
    "    device = torch_tensorrt.Device(\"cuda:0\"),\n",
    "    workspace_size=4194304\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfc2d534-36c5-4191-aefe-125ecdfede02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "cudnn.benchmark = True\n",
    "\n",
    "def benchmark(model, device=\"cuda:0\", input_shape=(1, 3, 384, 640), dtype='fp32', nwarmup=50, nruns=100):\n",
    "    if dtype == 'fp16':\n",
    "        input_data = torch.randn(input_shape, dtype = torch.half)\n",
    "    else:\n",
    "        input_data = torch.randn(input_shape)\n",
    "    # input_data.half()\n",
    "    input_data = input_data.to(device)\n",
    "        \n",
    "    print(\"Warm up ...\")\n",
    "    with torch.no_grad():\n",
    "        for _ in range(nwarmup):\n",
    "            features = model(input_data)\n",
    "    torch.cuda.synchronize()\n",
    "    print(\"Start timing ...\")\n",
    "    timings = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(1, nruns+1):\n",
    "            start_time = time.time()\n",
    "            features = model(input_data)\n",
    "            torch.cuda.synchronize()\n",
    "            end_time = time.time()\n",
    "            timings.append(end_time - start_time)\n",
    "            if i%10==0:\n",
    "                print('Iteration %d/%d, ave batch time %.2f ms'%(i, nruns, np.mean(timings)*1000))\n",
    "\n",
    "    print(\"Input shape:\", input_data.size())\n",
    "    # print(\"Output features size:\", features.size())\n",
    "    print('Average batch time: %.2f ms'%(np.mean(timings)*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9f1b19a4-8bb3-4ac7-8f96-461bd889ac1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm up ...\n",
      "Start timing ...\n",
      "Iteration 10/100, ave batch time 10.96 ms\n",
      "Iteration 20/100, ave batch time 10.30 ms\n",
      "Iteration 30/100, ave batch time 10.15 ms\n",
      "Iteration 40/100, ave batch time 10.03 ms\n",
      "Iteration 50/100, ave batch time 10.10 ms\n",
      "Iteration 60/100, ave batch time 10.09 ms\n",
      "Iteration 70/100, ave batch time 10.05 ms\n",
      "Iteration 80/100, ave batch time 10.04 ms\n",
      "Iteration 90/100, ave batch time 10.01 ms\n",
      "Iteration 100/100, ave batch time 9.97 ms\n",
      "Input shape: torch.Size([1, 3, 384, 640])\n",
      "Average batch time: 9.97 ms\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "model_half = copy.deepcopy(load_model).half()\n",
    "benchmark(model_half, dtype='fp16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1860e05f-f0aa-45fc-acca-72ffa73c4c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm up ...\n",
      "Start timing ...\n",
      "Iteration 10/100, ave batch time 15.64 ms\n",
      "Iteration 20/100, ave batch time 15.95 ms\n",
      "Iteration 30/100, ave batch time 15.88 ms\n",
      "Iteration 40/100, ave batch time 15.84 ms\n",
      "Iteration 50/100, ave batch time 15.77 ms\n",
      "Iteration 60/100, ave batch time 15.79 ms\n",
      "Iteration 70/100, ave batch time 15.78 ms\n",
      "Iteration 80/100, ave batch time 15.79 ms\n",
      "Iteration 90/100, ave batch time 15.79 ms\n",
      "Iteration 100/100, ave batch time 15.78 ms\n",
      "Input shape: torch.Size([1, 3, 384, 640])\n",
      "Average batch time: 15.78 ms\n"
     ]
    }
   ],
   "source": [
    "benchmark(load_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9749a346-fe58-4a0f-a354-5dd05007502d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm up ...\n",
      "Start timing ...\n",
      "Iteration 10/100, ave batch time 1.14 ms\n",
      "Iteration 20/100, ave batch time 1.12 ms\n",
      "Iteration 30/100, ave batch time 1.11 ms\n",
      "Iteration 40/100, ave batch time 1.11 ms\n",
      "Iteration 50/100, ave batch time 1.11 ms\n",
      "Iteration 60/100, ave batch time 1.10 ms\n",
      "Iteration 70/100, ave batch time 1.10 ms\n",
      "Iteration 80/100, ave batch time 1.10 ms\n",
      "Iteration 90/100, ave batch time 1.10 ms\n",
      "Iteration 100/100, ave batch time 1.10 ms\n",
      "Input shape: torch.Size([1, 3, 384, 640])\n",
      "Average batch time: 1.10 ms\n"
     ]
    }
   ],
   "source": [
    "benchmark(trt_model_half, dtype='fp16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "307ebb1b-617a-4e73-8eaf-97bfe55c12ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm up ...\n",
      "Start timing ...\n",
      "Iteration 10/100, ave batch time 14.61 ms\n",
      "Iteration 20/100, ave batch time 14.90 ms\n",
      "Iteration 30/100, ave batch time 14.90 ms\n",
      "Iteration 40/100, ave batch time 14.92 ms\n",
      "Iteration 50/100, ave batch time 14.86 ms\n",
      "Iteration 60/100, ave batch time 14.90 ms\n",
      "Iteration 70/100, ave batch time 14.86 ms\n",
      "Iteration 80/100, ave batch time 14.86 ms\n",
      "Iteration 90/100, ave batch time 14.88 ms\n",
      "Iteration 100/100, ave batch time 14.91 ms\n",
      "Input shape: torch.Size([1, 3, 384, 640])\n",
      "Average batch time: 14.91 ms\n"
     ]
    }
   ],
   "source": [
    "benchmark(trt_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c8bbfc2-c7e4-4709-9fd0-4f4335b93cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [Torch-TensorRT] - Input 0 of engine __torch___models_yolo_DetectionModel_trt_engine_0x51092d60 was found to be on cpu but should be on cuda:0. This tensor is being moved by the runtime but for performance considerations, ensure your inputs are all on GPU and open an issue here (https://github.com/pytorch/TensorRT/issues) if this warning persists.\n",
      "WARNING: [Torch-TensorRT] - Input 0 of engine __torch___models_yolo_DetectionModel_trt_engine_0x51092f70 was found to be on cpu but should be on cuda:0. This tensor is being moved by the runtime but for performance considerations, ensure your inputs are all on GPU and open an issue here (https://github.com/pytorch/TensorRT/issues) if this warning persists.\n",
      "WARNING: [Torch-TensorRT] - Input 1 of engine __torch___models_yolo_DetectionModel_trt_engine_0x51092f70 was found to be on cpu but should be on cuda:0. This tensor is being moved by the runtime but for performance considerations, ensure your inputs are all on GPU and open an issue here (https://github.com/pytorch/TensorRT/issues) if this warning persists.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\nRuntimeError: [Error thrown at core/runtime/execute_engine.cpp:136] Expected inputs[i].dtype() == expected_type to be true but got false\nExpected input tensors to have type Half, found type float\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrt_model_half\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m384\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m640\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhalf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\nRuntimeError: [Error thrown at core/runtime/execute_engine.cpp:136] Expected inputs[i].dtype() == expected_type to be true but got false\nExpected input tensors to have type Half, found type float\n\n"
     ]
    }
   ],
   "source": [
    "trt_model_half(torch.randn((1, 3, 384, 640), dtype = torch.half))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a617d81-4ccf-4277-833b-6d2acf105c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "teste = torch.randn((1, 3, 384, 640), dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1378e8c7-30df-40ed-952d-ea5a4f03477d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.1689,  0.0921,  1.7334,  ...,  1.1240, -0.9038, -1.4434],\n",
       "          [-0.0855,  0.6484,  0.1616,  ..., -0.5337, -1.3232, -0.3740],\n",
       "          [-0.6460,  0.3330, -0.0072,  ...,  0.5352,  1.4834,  1.0596],\n",
       "          ...,\n",
       "          [-0.9326,  0.8481, -0.3757,  ...,  1.0459,  0.3838, -0.6147],\n",
       "          [ 0.8218, -1.5693, -0.7974,  ...,  1.5107, -0.9663, -0.0483],\n",
       "          [ 1.7832, -1.4648, -0.8350,  ...,  0.5840, -0.8550,  0.7383]],\n",
       "\n",
       "         [[-1.3564, -0.6748, -0.3154,  ...,  0.4971,  0.0774,  1.5732],\n",
       "          [-0.0685,  0.3486,  0.4094,  ..., -0.7871,  0.3789, -1.7520],\n",
       "          [-0.0982, -0.6846,  1.2363,  ..., -1.0967,  0.5737, -1.5830],\n",
       "          ...,\n",
       "          [ 0.5210, -0.8164, -0.7412,  ...,  1.1729,  0.7275, -1.8613],\n",
       "          [ 0.5464, -0.0115,  0.2756,  ...,  0.9985,  1.8457,  1.5156],\n",
       "          [-0.5640, -0.8818,  0.3110,  ..., -0.3245,  0.1918,  0.9941]],\n",
       "\n",
       "         [[-0.1318, -1.9062, -0.3010,  ...,  0.6899, -0.2499,  0.7744],\n",
       "          [ 0.2620,  0.5225,  0.1969,  ..., -0.3706, -0.7178,  1.8301],\n",
       "          [-0.8584,  0.0621,  0.1249,  ..., -1.4492,  1.0615,  0.3723],\n",
       "          ...,\n",
       "          [ 0.6289,  0.6260, -1.0703,  ...,  0.8550, -0.5918, -0.2318],\n",
       "          [-0.4045, -0.3884, -1.0898,  ...,  0.5747,  0.6284,  0.0904],\n",
       "          [ 2.1602, -1.5938, -0.4290,  ..., -0.0635, -2.2402,  0.2227]]]],\n",
       "       dtype=torch.float16)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste.half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad7582ef-abda-45ac-820a-9312b6570454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch_tensorrt._Input.Input at 0x7f12c4389790>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_tensorrt.Input((1, 3, 384, 640), dtype=torch_tensorrt.dtype.half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ff45286-8d92-4399-bc36-89127efaefea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [Torch-TensorRT] - Input 0 of engine __torch___models_yolo_DetectionModel_trt_engine_0xe8860190 was found to be on cpu but should be on cuda:0. This tensor is being moved by the runtime but for performance considerations, ensure your inputs are all on GPU and open an issue here (https://github.com/pytorch/TensorRT/issues) if this warning persists.\n",
      "WARNING: [Torch-TensorRT] - Input 0 of engine __torch___models_yolo_DetectionModel_trt_engine_0xe88603a0 was found to be on cpu but should be on cuda:0. This tensor is being moved by the runtime but for performance considerations, ensure your inputs are all on GPU and open an issue here (https://github.com/pytorch/TensorRT/issues) if this warning persists.\n",
      "WARNING: [Torch-TensorRT] - Input 1 of engine __torch___models_yolo_DetectionModel_trt_engine_0xe88603a0 was found to be on cpu but should be on cuda:0. This tensor is being moved by the runtime but for performance considerations, ensure your inputs are all on GPU and open an issue here (https://github.com/pytorch/TensorRT/issues) if this warning persists.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\nRuntimeError: [Error thrown at core/runtime/execute_engine.cpp:136] Expected inputs[i].dtype() == expected_type to be true but got false\nExpected input tensors to have type Half, found type float\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrt_model_half\u001b[49m\u001b[43m(\u001b[49m\u001b[43mteste\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\nRuntimeError: [Error thrown at core/runtime/execute_engine.cpp:136] Expected inputs[i].dtype() == expected_type to be true but got false\nExpected input tensors to have type Half, found type float\n\n"
     ]
    }
   ],
   "source": [
    "trt_model_half(teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3357d0ce-467e-47ad-9c6c-825ea40d2c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'torch_tensorrt' from '/home/gribeiro/.local/lib/python3.8/site-packages/torch_tensorrt/__init__.py'>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_tensorrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d2abe3d-1446-44bb-8210-641b09c7cdfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1+cu117'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
